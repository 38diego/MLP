{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaKd4YlEeDkJ"
      },
      "outputs": [],
      "source": [
        "# Desactiva las advertencias para evitar saturar la salida con mensajes irrelevantes.\n",
        "# Esto es útil en casos donde sabemos que las advertencias no afectan el entrenamiento.\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61E6YiJtvcWL",
        "outputId": "328763ff-770d-4b70-b7fa-ccb0707c2022"
      },
      "outputs": [],
      "source": [
        "# Verifica la versión de TensorFlow\n",
        "# Es importante comprobar la versión para asegurar compatibilidad con el código.\n",
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BImMwe5Bad_F"
      },
      "outputs": [],
      "source": [
        "# Lista todos los paquetes instalados en el entorno actual junto con sus versiones.\n",
        "# Esto es útil para verificar las dependencias y asegurarse de que las versiones son correctas.\n",
        "# Ordena los paquetes por nombre antes de mostrarlos\n",
        "#installed_packages = sorted(pkg_resources.working_set, key=lambda x: x.key)\n",
        "#for package in installed_packages:\n",
        "#    print(f\"{package.key}=={package.version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPRSFoipeDkK"
      },
      "outputs": [],
      "source": [
        "# Importa módulos y librerías necesarias\n",
        "import numpy as np  # Biblioteca para operaciones matemáticas y manejo de matrices\n",
        "import matplotlib.pyplot as plt  # Para graficar datos y visualizar resultados\n",
        "\n",
        "# Importa el conjunto de datos MNIST, un dataset clásico para clasificación de dígitos escritos a mano\n",
        "from tf_keras.datasets import mnist\n",
        "from tf_keras import models, layers\n",
        "from tf_keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GVewRxreDkK"
      },
      "source": [
        "## Cargamos los datos de MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk5pLrG7eDkK",
        "outputId": "9c0b7c85-91e8-4b8b-d7db-94878ed8f47d"
      },
      "outputs": [],
      "source": [
        "# Carga el conjunto de datos MNIST\n",
        "# Este dataset contiene imágenes de dígitos escritos a mano (28x28 píxeles en escala de grises)\n",
        "# Se divide en datos de entrenamiento y prueba, junto con sus etiquetas correspondientes\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-GymcAweDkK",
        "outputId": "74bf2933-a793-457e-cb81-ce1bf175afa1"
      },
      "outputs": [],
      "source": [
        "# Algo de información sobre los datos de entrenamiento\n",
        "print(\"=== Información sobre los datos ===\")\n",
        "\n",
        "# Información sobre las entradas\n",
        "print(\"Entradas (imágenes):\")\n",
        "print(f\"  Tipo de dato: {type(train_images)}\")\n",
        "print(f\"  Dimensiones: {train_images.shape}\")\n",
        "print(f\"  Tipo de contenido: {train_images.dtype}\\n\")\n",
        "\n",
        "# Información sobre las etiquetas\n",
        "print(\"Etiquetas (labels):\")\n",
        "print(f\"  Tipo de dato: {type(train_labels)}\")\n",
        "print(f\"  Dimensiones: {train_labels.shape}\")\n",
        "print(f\"  Valores únicos: {set(train_labels)}\")\n",
        "\n",
        "print()\n",
        "# Información sobre los datos de prueba\n",
        "print(\"=== Información sobre los datos de prueba ===\")\n",
        "\n",
        "# Información sobre las entradas (imágenes)\n",
        "print(\"Entradas (imágenes):\")\n",
        "print(f\"  Tipo de dato: {type(test_images)}\")  # Tipo de datos (numpy.ndarray)\n",
        "print(f\"  Dimensiones: {test_images.shape}\")  # Dimensiones de las imágenes\n",
        "print(f\"  Tipo de contenido: {test_images.dtype}\")  # Tipo de valores almacenados (por ejemplo, uint8)\n",
        "\n",
        "# Información sobre las etiquetas\n",
        "print(\"\\nEtiquetas:\")\n",
        "print(f\"  Tipo de dato: {type(test_labels)}\")  # Tipo de datos (numpy.ndarray)\n",
        "print(f\"  Dimensiones: {test_labels.shape}\")  # Dimensiones de las etiquetas\n",
        "print(f\"  Valores únicos: {set(test_labels)}\")  # Valores únicos en las etiquetas (clases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRU_sVwg1-4t"
      },
      "source": [
        "## Apropiamos los datos de MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkgVCftGexJD",
        "outputId": "ffef9ed5-b8cf-4581-ec87-fceb21a2d100"
      },
      "outputs": [],
      "source": [
        "# Configura NumPy para mostrar la matriz completa sin recortes\n",
        "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
        "\n",
        "indice = 0\n",
        "\n",
        "# Muestra la matriz completa de píxeles de la imagen\n",
        "print(f\"\\nMatriz de píxeles de la imagen en el índice {indice}:\",end = \"\\n\\n\")\n",
        "print(train_images[indice])\n",
        "# Restablece las opciones de impresión de NumPy a sus valores predeterminados\n",
        "np.set_printoptions(threshold=1000, linewidth=75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "wCRXC9-LyERU",
        "outputId": "3d7cca98-3ed4-48e0-b711-6ceb07afc471"
      },
      "outputs": [],
      "source": [
        "plt.imshow(train_images[indice], cmap='gray')  # Muestra la imagen en escala de grises\n",
        "plt.title(f\"Etiqueta: {train_labels[indice]}\")  # Asigna un título a la imagen\n",
        "plt.axis('off')  # Desactiva los ejes de la imagen\n",
        "plt.show()\n",
        "#0 --> negro\n",
        "#255 --> blanco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTU0AWKc1k3C",
        "outputId": "a37268e4-5339-47ee-87aa-7cd348f90b26"
      },
      "outputs": [],
      "source": [
        "# Muestra la etiqueta correspondiente\n",
        "print(f\"Etiqueta de la imagen en el índice {indice}: {train_labels[indice]}\")\n",
        "\n",
        "# Muestra las primeras 10 etiquetas como ejemplo\n",
        "print(\"\\nEjemplo de etiquetas (primeros 10 valores):\")\n",
        "print(train_labels[:10])  # Muestra un subconjunto de etiquetas\n",
        "\n",
        "# Explicación adicional sobre el formato de las etiquetas\n",
        "print(\"\\nLas etiquetas son números enteros que representan los dígitos escritos a mano en las imágenes.\")\n",
        "print(\"Por ejemplo:\")\n",
        "for i, label in enumerate(train_labels[:5]):\n",
        "    print(f\" - Etiqueta {i}: {label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRWNr5hteDkL"
      },
      "source": [
        "# Una RNA en keras\n",
        "## Arquitectura"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdwelbB68HHB"
      },
      "source": [
        "### Estilo Secuencial\n",
        "Este enfoque es ideal para arquitecturas lineales (es decir, cada capa tiene exactamente una entrada y una salida).\n",
        "\n",
        "- Simple y claro: Fácil de leer y mantener.\n",
        "- Limitado: No admite arquitecturas complejas como múltiples entradas, múltiples salidas o conexiones entre capas que no sean estrictamente secuenciales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HSORDwHeDkL",
        "outputId": "d246e863-7144-43a9-ba6b-168f7a2db8b9"
      },
      "outputs": [],
      "source": [
        "net = models.Sequential()\n",
        "net.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "net.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "mHkF_icRJaO6",
        "outputId": "4365d1d6-b82b-4448-bd65-5cb6c3cf6b98"
      },
      "outputs": [],
      "source": [
        "net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr2eLvR6xOmL"
      },
      "outputs": [],
      "source": [
        "net2 = models.Sequential()\n",
        "net2.add(layers.Input(shape=(28 * 28,), name = \"sapito1\"))\n",
        "net2.add(layers.Dense(512, activation='relu', name = \"sapito2\"))\n",
        "net2.add(layers.Dense(10, activation='softmax', name = \"sapito3\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "aQo3-nvWJcPR",
        "outputId": "31520907-8fc3-4715-df7f-c6341e92f2a7"
      },
      "outputs": [],
      "source": [
        "net2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFwoxYpb8MPi"
      },
      "source": [
        "### Estilo Funcional\n",
        "Permite definir modelos más complejos, incluyendo arquitecturas con múltiples entradas y salidas, bifurcaciones y conexiones no lineales.\n",
        "- Flexible: Admite arquitecturas complejas (por ejemplo, modelos con múltiples entradas y salidas).\n",
        "- Legible: Define claramente el flujo de datos entre capas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISYGY8Convgc"
      },
      "outputs": [],
      "source": [
        "from tf_keras import Input,Model\n",
        "\n",
        "entrada = Input(shape=(28 * 28,))\n",
        "capa1 = layers.Dense(512, activation='relu')(entrada)\n",
        "capa2 = layers.Dense(10, activation='softmax')(capa1)\n",
        "\n",
        "network = Model(inputs=entrada, outputs=capa2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLi_9ew88rBe"
      },
      "source": [
        "### Estilo Subclassing\n",
        "Permite definir tu propio modelo heredando de la clase tf.keras.Model. Es el más flexible, ya que te da control total sobre las operaciones realizadas en el modelo.\n",
        "\n",
        "- Extremadamente flexible: Puedes definir cualquier operación personalizada.\n",
        "- Requiere más código: Menos automatización, más control manual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "f9GQ1m3D4cBt",
        "outputId": "f505e6d4-112b-40f8-d55c-3a5d290fbdef"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model\n",
        "\n",
        "class MiRedcita(Model):\n",
        "    def __init__(self):\n",
        "        super(MiRedcita, self).__init__()\n",
        "        self.densa1 = layers.Dense(512, activation='relu')\n",
        "        self.densa2 = layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.densa1(inputs)\n",
        "        return self.densa2(x)\n",
        "\n",
        "    def build_model(self):\n",
        "        x = Input(shape=(28 * 28,))\n",
        "        return Model(inputs=x, outputs=self.call(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_B_ohk1_MLN"
      },
      "source": [
        "## Resumen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "ItrrDaqkeDkL",
        "outputId": "769fa4aa-b2e8-4cb9-e024-6da6822eb4b0"
      },
      "outputs": [],
      "source": [
        "net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "i-7TD6O1_e7Y",
        "outputId": "dbc79c66-843e-448e-ae49-7f0a829aeda6"
      },
      "outputs": [],
      "source": [
        "from tf_keras.utils import plot_model\n",
        "\n",
        "# Guardar el modelo como una imagen con plot_model\n",
        "plot_model(\n",
        "    net,\n",
        "    to_file='network_dibujadita.png',\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    dpi=50\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz57wEx8Cvoy"
      },
      "source": [
        "## Compilación\n",
        "Define cómo se entrenará el modelo, cómo se medirá su desempeño y cómo se actualizarán los pesos de la red."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_ZdVQH9eDkM"
      },
      "outputs": [],
      "source": [
        "net.compile(\n",
        "    # Define el optimizador que se utilizará para actualizar los pesos del modelo durante el entrenamiento\n",
        "    optimizer='rmsprop', # Descenso del gradiente\n",
        "\n",
        "    # Establece la función de pérdida que el modelo intentará minimizar\n",
        "    loss='categorical_crossentropy', # Entropia cruzada, que tanto se diferencian 2 distribuciones de probabilidad :V\n",
        "\n",
        "    # Lista de métricas a monitorear durante el entrenamiento y la evaluación\n",
        "    metrics=['accuracy',\n",
        "             'recall',\n",
        "             'precision',\n",
        "             'auc']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LutuTEHqO856"
      },
      "outputs": [],
      "source": [
        "from tf_keras.metrics import Recall, Precision, AUC, Accuracy, CategoricalAccuracy\n",
        "\n",
        "net.compile(\n",
        "    optimizer='rmsprop', # Descenso del gradiente\n",
        "    loss='categorical_crossentropy', # Entropia cruzada, que tanto se diferencian 2 distribuciones de probabilidad :V\n",
        "\n",
        "    metrics=[\n",
        "        Recall(name='recall'),\n",
        "        Precision(name='precision'),\n",
        "        AUC(name='auc'),\n",
        "        Accuracy(name='accuracy'),\n",
        "        CategoricalAccuracy(name='categorical_accuracy')\n",
        "        ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gypywi2oeDkM"
      },
      "source": [
        "# Pre procesamiento de datos\n",
        "## Vectorizar imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIY0OCY7eDkM",
        "outputId": "b2fe2793-afc4-4ba1-d618-fa667909df22"
      },
      "outputs": [],
      "source": [
        "# Mostrar el tamaño original de las imágenes de entrenamiento\n",
        "print('Tamaño original de las entradas de entrenamiento:', train_images.shape)\n",
        "print('Tamaño original de las entradas de pruebas:', test_images.shape)\n",
        "\n",
        "# Vectorizar las imágenes\n",
        "train_images = train_images.reshape((60000, 784))\n",
        "test_images = test_images.reshape((10000, 784))\n",
        "print('Tamaño vectorizado de las entradas de entrenamiento:', train_images.shape)\n",
        "print('Tamaño vectorizado de las entradas de prueba:', test_images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGLzKt1MEzFl"
      },
      "source": [
        "## Escalar pixeles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbTG99VeEVI9",
        "outputId": "4501531f-9520-4c38-a5ab-3a890e02e449"
      },
      "outputs": [],
      "source": [
        "# Mostrar algunos valores de píxeles antes del escalado\n",
        "print(\"Valores de píxeles de una imagen (sin escalar):\")\n",
        "for i, val in enumerate(train_images[0, 405:410]):\n",
        "    print(f\"  Pixel {405 + i}: {val}\")\n",
        "\n",
        "# Escalar los valores de píxeles a [0, 1]\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Mostrar los mismos valores de píxeles después del escalado\n",
        "print(\"\\nLos mismos valores de píxeles de una imagen escalados a [0, 1]:\")\n",
        "for i, val in enumerate(train_images[0, 405:410]):\n",
        "    print(f\"  Pixel {405 + i}: {val:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ae0RIgjHS3G"
      },
      "source": [
        "## Vectorizar etiquetas de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYMEQPYleDkM",
        "outputId": "568a3b21-0130-4001-f083-1035cbd69d50"
      },
      "outputs": [],
      "source": [
        "from tf_keras.utils import to_categorical\n",
        "\n",
        "# Codificación One-hot\n",
        "print(\"=== Codificación One-hot ===\")\n",
        "print(f\"Tamaño inicial de las etiquetas: {train_labels.shape}\")\n",
        "\n",
        "print(f\"Ejemplo de etiqueta antes de la codificación: {train_labels[0]}\")\n",
        "\n",
        "# Realizar la codificación One-hot\n",
        "train_labels_cod = to_categorical(train_labels)\n",
        "test_labels_cod = to_categorical(test_labels)\n",
        "\n",
        "print(f\"Ejemplo de etiqueta después de la codificación: {train_labels_cod[0]}\")\n",
        "\n",
        "print(f\"\\nTamaño de las etiquetas después de codificación One-hot: {train_labels_cod.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7rEzc1BHbiv"
      },
      "source": [
        "# Entrenar la red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEJRcEZceDkM",
        "outputId": "908b9084-1f8a-47f4-c128-5c98bc5b21fb",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Entrenamiento del modelo\n",
        "print(\"=== Entrenamiento del modelo ===\")\n",
        "\n",
        "H = net.fit(\n",
        "    train_images,\n",
        "    train_labels_cod,\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "\n",
        "# Resumen del proceso\n",
        "print(f\"\\nDatos utilizados en el entrenamiento:\")\n",
        "print(f\"- Datos de entrenamiento: {int(train_images.shape[0] * 0.8)} muestras\")\n",
        "print(f\"- Datos de validación: {int(train_images.shape[0] * 0.2)} muestras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6HWTjz1eDkM",
        "outputId": "22a915d3-93f3-4879-d2cb-c95b0933f583"
      },
      "outputs": [],
      "source": [
        "# Configuración del entrenamiento\n",
        "epoch = 5               # Número de épocas\n",
        "total_examples = 60000  # Número total de ejemplos\n",
        "validation_split = 0.2  # Porcentaje reservado para validación\n",
        "batch_size = 128        # Tamaño del lote\n",
        "\n",
        "# Calcular ejemplos de entrenamiento y validación\n",
        "training_examples = int(total_examples * (1 - validation_split))  # 48,000 ejemplos para entrenamiento\n",
        "validation_examples = int(total_examples * validation_split)      # 12,000 ejemplos para validación\n",
        "\n",
        "# Calcular los pasos totales\n",
        "steps_per_epoch = training_examples / batch_size  # Pasos por época para entrenamiento\n",
        "total_training_steps = steps_per_epoch * epoch    # Total de pasos para entrenamiento\n",
        "\n",
        "validation_steps = validation_examples / batch_size  # Pasos por época para validación\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"=== Configuración del entrenamiento ===\")\n",
        "print(f\"Total de ejemplos: {total_examples}\")\n",
        "print(f\"- Ejemplos para entrenamiento: {training_examples}\")\n",
        "print(f\"- Ejemplos para validación: {validation_examples}\")\n",
        "print(f\"Tamaño del lote: {batch_size}\")\n",
        "\n",
        "print(\"\\n=== Cálculo de pasos ===\")\n",
        "print(f\"Pasos por época (entrenamiento): {int(steps_per_epoch)}\")\n",
        "print(f\"Pasos totales (entrenamiento): {int(total_training_steps)}\")\n",
        "print(f\"Pasos por época (validación): {int(validation_steps)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "VYJ_RN64IBXd",
        "outputId": "7a5f2ec3-4c68-4c8b-ff2a-09e4edc7f913"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "model.fit(\n",
        "    x,                    # Datos de entrada\n",
        "    y,                    # Etiquetas (objetivo)\n",
        "    batch_size=None,      # Tamaño del lote\n",
        "    epochs=1,             # Número de épocas\n",
        "    verbose=1,            # Nivel de detalle en la salida\n",
        "    callbacks=None,       # Lista de callbacks para personalizar el entrenamiento\n",
        "    validation_split=0.0, # Proporción de datos reservados para validación\n",
        "    validation_data=None, # Datos específicos para validación (x_val, y_val)\n",
        "    shuffle=True,         # Barajar los datos en cada época\n",
        "    class_weight=None,    # Ponderación de clases para manejar desequilibrio\n",
        "    sample_weight=None,   # Ponderación por muestra\n",
        "    initial_epoch=0,      # Época inicial (útil al reanudar entrenamiento)\n",
        "    steps_per_epoch=None, # Número de pasos por época (cuando x es un generador)\n",
        "    validation_steps=None,# Pasos de validación por época (cuando validation_data es un generador)\n",
        "    validation_batch_size=None, # Tamaño del lote para validación\n",
        "    validation_freq=1,    # Frecuencia de validación (cada cuántas épocas validar)\n",
        "    max_queue_size=10,    # Tamaño de la cola para datos generados\n",
        "    workers=1,            # Número de hilos de procesamiento para generadores\n",
        "    use_multiprocessing=False # Usar multiprocesamiento con generadores\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAyjflQMI_uU"
      },
      "source": [
        "> Un generador es un objeto o función que produce datos de forma secuencial, en lugar de cargar todo el conjunto de datos en memoria al mismo tiempo. Los generadores son especialmente útiles cuando trabajas con conjuntos de datos grandes que no caben en la memoria RAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEYmy46QeDkM"
      },
      "source": [
        "# Probamos el modelo\n",
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zmrcTOyeDkM",
        "outputId": "088623ef-0df8-44c9-f4c1-69cc755a197f"
      },
      "outputs": [],
      "source": [
        "# Evaluación del modelo en datos de prueba\n",
        "print(\"=== Evaluación del modelo en datos no conocidos ===\")\n",
        "\n",
        "# Evaluar el modelo en el conjunto de prueba\n",
        "results = net.evaluate(\n",
        "    test_images,\n",
        "    test_labels_cod,\n",
        ")\n",
        "\n",
        "# Mostrar los resultados de evaluación\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6CmChZNVqkZ",
        "outputId": "375d89c6-7fcb-42cd-f24c-6e1909977e60"
      },
      "outputs": [],
      "source": [
        "print(f\"Tamaño de 'results' (evaluate): {len(results)}\")  # Número de métricas + pérdida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gm-74VGVyO3",
        "outputId": "49307d43-61f5-40cd-b4d0-bc864aa8287a"
      },
      "outputs": [],
      "source": [
        "# Mostrar los resultados de evaluación\n",
        "print(\"\\nResultados del modelo en el conjunto de prueba:\")\n",
        "print(f\"- Pérdida (Loss): {results[0]:.4f}\")\n",
        "print(f\"- Precisión (Accuracy): {results[1]:.4f}\")\n",
        "print(f\"- Recall: {results[2]:.4f}\")\n",
        "print(f\"- Precisión (Precision): {results[3]:.4f}\")\n",
        "print(f\"- AUC: {results[4]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-txQrWmgPUX6"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QUt01goTKNY",
        "outputId": "92fd0c85-41a7-4857-fb55-8acd281b303b"
      },
      "outputs": [],
      "source": [
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = net.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d56Xnq_-TiF5",
        "outputId": "f7f412d0-621e-49b1-d403-a0cd0458bb36"
      },
      "outputs": [],
      "source": [
        "# Mostrar el tamaño de y_pred\n",
        "print(f\"Tamaño de 'y_pred' (predict): {y_pred.shape}\")\n",
        "\n",
        "indice=0\n",
        "# Mostrar las probabilidades de predicción para una imagen en formato vertical\n",
        "print(f\"\\nPredicción para una imagen: {y_pred[indice]}\")\n",
        "\n",
        "print(\"\\nPredicción para una imagen (formato vertical):\")\n",
        "for i, prob in enumerate(y_pred[indice]):\n",
        "    print(f\"Clase {i}: {prob:.16f}\")\n",
        "\n",
        "# Clase predicha (con mayor probabilidad)\n",
        "predicted_class = y_pred[0].argmax()\n",
        "print(f\"\\nClase predicha para esta imagen: {predicted_class}\")\n",
        "\n",
        "# Clase real (etiqueta real)\n",
        "real_class = test_labels[0]  # Si las etiquetas están en formato numérico\n",
        "print(f\"Etiqueta real para esta imagen: {real_class}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET4GSfR6WTrK",
        "outputId": "a6ffd481-dcb2-497a-b585-b042a9c563b5"
      },
      "outputs": [],
      "source": [
        "y_pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj-YOTLNOuzn",
        "outputId": "c1a93ba6-8cff-41de-82c3-65931ebdc563"
      },
      "outputs": [],
      "source": [
        "# Convertir probabilidades a clases predichas\n",
        "y_pred_classes = net.predict(test_images).argmax(axis=1)\n",
        "\n",
        "# Generar el reporte de clasificación\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(\n",
        "    test_labels,              # Etiquetas reales (en enteros)\n",
        "    y_pred_classes,              # Etiquetas predichas (en enteros)\n",
        "    target_names=[f\"Clase {i}\" for i in range(10)],  # Nombres de las clases\n",
        "    digits=4\n",
        ")\n",
        "\n",
        "print(\"=== Classification Report ===\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aUtGXpKWQnH",
        "outputId": "6276148a-0aa6-44c1-fa6a-1bf55f6ab25f"
      },
      "outputs": [],
      "source": [
        "y_pred_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnYskC6IY6TV"
      },
      "source": [
        "### ¿Qué hacen exactamente `evaluate` y `predict`?\n",
        "\n",
        "#### **`evaluate`**:\n",
        "1. Divide los datos en lotes.\n",
        "2. Calcula las métricas y la pérdida para cada lote.\n",
        "3. Promedia los resultados en todos los lotes.\n",
        "\n",
        "#### **`predict`**:\n",
        "1. Divide los datos en lotes.\n",
        "2. Calcula las predicciones para cada lote.\n",
        "3. Devuelve las predicciones concatenadas para todo el conjunto de datos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-TsGZBreDkN"
      },
      "source": [
        "## Visualizamos el desempeño de la red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k8N6uQheDkN",
        "outputId": "84a45302-9c0c-4108-9b00-9f899f9a0839"
      },
      "outputs": [],
      "source": [
        "# Mostrar las claves del historial de entrenamiento\n",
        "print(\"=== Keys en el historial de entrenamiento ===\")\n",
        "for key in H.history.keys():\n",
        "    print(f\"- {key}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "laBA2vLYeDkN",
        "outputId": "93eb4674-9b5b-403c-c504-895baf800a8c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "# Obtener las métricas del historial\n",
        "history = H.history\n",
        "metrics = ['accuracy', 'auc', 'loss', 'precision', 'recall']  # Métricas de entrenamiento\n",
        "val_metrics = [f\"val_{metric}\" for metric in metrics]         # Métricas de validación\n",
        "\n",
        "# Configuración de los subplots\n",
        "num_metrics = len(metrics)\n",
        "num_rows = 3  # Número de filas\n",
        "num_cols = math.ceil(num_metrics / num_rows)  # Columnas necesarias\n",
        "\n",
        "# Tamaño más compacto de la figura\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 6))\n",
        "\n",
        "# Aplanar los ejes para facilitar la iteración\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Crear gráficos para cada métrica\n",
        "for i, metric in enumerate(metrics):\n",
        "    ax = axes[i]\n",
        "\n",
        "    # Graficar métricas de entrenamiento y validación\n",
        "    ax.plot(history[metric], label=f'Train {metric}', marker='o', linestyle='-')\n",
        "    ax.plot(history[val_metrics[i]], label=f'Validation {metric}', marker='x', linestyle='--')\n",
        "\n",
        "    # Configuración del subplot\n",
        "    ax.set_title(f'Evolución de {metric}', fontsize=10)\n",
        "    ax.set_ylabel(metric.capitalize(), fontsize=8)\n",
        "    ax.legend(fontsize=8)\n",
        "    ax.grid(True)\n",
        "\n",
        "# Limpiar subplots vacíos si hay menos métricas que subplots\n",
        "for j in range(len(metrics), len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "# Ajustar espaciado entre subplots\n",
        "plt.tight_layout(pad=1.0)  # Ajustar márgenes entre gráficos\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89M09rlCeDkN"
      },
      "source": [
        "# Jugamos a predecir con la red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "w8cgEHSmeTk1",
        "outputId": "4d19190b-d36d-4fa2-e0ca-45d480bcf828"
      },
      "outputs": [],
      "source": [
        "# Índice de una imagen\n",
        "img_no = 877\n",
        "\n",
        "# Selección de la imagen\n",
        "img = test_images[img_no, :]\n",
        "\n",
        "# Tamaño original de la imagen\n",
        "print(f\"\\nTamaño actual de la imagen: {img.shape}\")\n",
        "\n",
        "# Reformar la imagen para visualizarla correctamente\n",
        "img = img.reshape((28, 28))\n",
        "img = img.astype('float32') * 255  # Reescalar a rango 0-255 para visualización\n",
        "print(f\"Tamaño reformado de la imagen: {img.shape}\")\n",
        "\n",
        "# Visualización de la imagen\n",
        "plt.imshow(img, cmap=plt.cm.gray_r)\n",
        "plt.title(f\"Índice: {img_no}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Etiqueta correspondiente\n",
        "print(f\"Etiqueta real : {np.argmax(test_labels_cod[img_no])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIG1lAHdgMVG",
        "outputId": "9dbb8d0a-ab78-4ef5-d8cc-2b8672b1b81f"
      },
      "outputs": [],
      "source": [
        "# Predicción del modelo\n",
        "prediccion = net.predict(test_images[img_no:img_no+1])\n",
        "prediccion_class = prediccion.argmax()\n",
        "\n",
        "print(f\"Clase predicha: {prediccion}\")\n",
        "\n",
        "# Mostrar las probabilidades en formato vertical\n",
        "print(\"\\n=== Predicción del modelo ===\")\n",
        "print(\"Probabilidades por clase:\")\n",
        "for i, prob in enumerate(prediccion[0]):  # Iterar sobre las probabilidades de cada clase\n",
        "    print(f\"Clase {i}: {prob:.16f}\")\n",
        "\n",
        "# Mostrar la clase predicha\n",
        "print(f\"\\nClase predicha: {prediccion_class}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "a2l_XczMpX9t",
        "outputId": "7148d2ac-a82c-4a8f-d4ef-baddc48e4510"
      },
      "outputs": [],
      "source": [
        "# Distribución real (etiqueta real en formato one-hot)\n",
        "real_distribution = test_labels_cod[img_no]\n",
        "\n",
        "# Crear el gráfico con dos histogramas lado a lado\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
        "\n",
        "# Histograma de la predicción\n",
        "ax1.bar(range(10), prediccion[0], edgecolor='black', color='blue', align='center')\n",
        "ax1.set_title(f'Predicción de probabilidades para la imagen {img_no}', fontsize=8)\n",
        "ax1.set_ylabel('Probabilidad', fontsize=8)\n",
        "ax1.set_xlabel('Clase', fontsize=8)\n",
        "ax1.set_xticks(range(10))\n",
        "ax1.set_xticklabels([str(i) for i in range(10)], fontsize=8)\n",
        "ax1.set_ylim(0, 1)\n",
        "\n",
        "# Añadir etiquetas sobre las barras del histograma de predicción\n",
        "for i, prob in enumerate(prediccion[0]):\n",
        "    ax1.text(i, prob + 0.02, f'{prob:.2f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "# Histograma de la etiqueta real\n",
        "ax2.bar(range(10), real_distribution, edgecolor='black', color='green', align='center')\n",
        "ax2.set_title(f'Distribución real', fontsize=8)\n",
        "ax2.set_ylabel('Probabilidad', fontsize=8)\n",
        "ax2.set_xlabel('Clase', fontsize=8)\n",
        "ax2.set_xticks(range(10))\n",
        "ax2.set_xticklabels([str(i) for i in range(10)], fontsize=8)\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "# Añadir etiquetas sobre las barras del histograma de la etiqueta real\n",
        "for i, prob in enumerate(real_distribution):\n",
        "    ax2.text(i, prob + 0.02, f'{prob:.2f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "# Ajustar diseño para que las gráficas no se solapen\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Mostrar la clase predicha y la etiqueta real en la consola\n",
        "print(f\"\\nClase predicha: {prediccion_class}\")\n",
        "print(f\"Etiqueta real: {np.argmax(real_distribution)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnKVnfM9cnMD",
        "outputId": "ff043c51-e895-462b-fc3b-a03e0be9f494"
      },
      "outputs": [],
      "source": [
        "# Umbral de baja confianza\n",
        "low_confidence_threshold = 0.2\n",
        "\n",
        "# Realizar predicciones para todo el conjunto de prueba\n",
        "predictions = network.predict(test_images)\n",
        "predicted_classes = np.argmax(predictions, axis=1)  # Clases predichas\n",
        "true_classes = np.argmax(test_labels_cod, axis=1)   # Clases reales\n",
        "\n",
        "# Identificar predicciones con baja confianza\n",
        "low_confidence_indices = []\n",
        "for i, pred in enumerate(predictions):\n",
        "    predicted_class = predicted_classes[i]\n",
        "    confidence = pred[predicted_class]  # Probabilidad de la clase predicha\n",
        "    if confidence < low_confidence_threshold:\n",
        "        low_confidence_indices.append((i, predicted_class, confidence))\n",
        "\n",
        "# Mostrar las primeras 10 predicciones con baja confianza\n",
        "print(\"=== Predicciones con baja confianza ===\")\n",
        "for idx, predicted_class, confidence in low_confidence_indices[:10]:\n",
        "    print(f\"Índice: {idx}, Clase predicha: {predicted_class}, Confianza: {confidence:.4f}\")\n",
        "\n",
        "print(f\"\\nTotal de predicciones con baja confianza: {len(low_confidence_indices)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "bwTNp_EecwO9",
        "outputId": "632a5ed6-9d92-4ad7-c2cc-01009698e6fb"
      },
      "outputs": [],
      "source": [
        "# Configuración de subplots para mostrar varias imágenes en una sola figura\n",
        "fig, axes = plt.subplots(3, 5, figsize=(8, 6))  # 3 filas, 5 columnas\n",
        "axes = axes.ravel()  # Aplanar la matriz de subplots para iterar fácilmente\n",
        "\n",
        "for i, (idx, _, _) in enumerate(low_confidence_indices[:15]):\n",
        "    # Restaurar el tamaño y reescalar para visualización\n",
        "    img = test_images[idx].reshape((28, 28))\n",
        "    img = img.astype('float32') * 255\n",
        "\n",
        "    # Mostrar cada imagen en un subplot\n",
        "    axes[i].imshow(img, cmap='gray')\n",
        "    axes[i].set_title(f\"Índice: {idx}\\nReal: {test_labels[idx]}\\nPred: {y_pred_classes[idx]}\", fontsize=8)\n",
        "    axes[i].axis('off')  # Ocultar ejes\n",
        "\n",
        "# Ajustar el diseño para evitar solapamientos\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEnvps576Z6e"
      },
      "source": [
        "# Laboratorio 1\n",
        "\n",
        "---\n",
        "\n",
        "## Ejercicio 1: Optimización de Hiperparámetros para Máxima Precisión\n",
        "\n",
        "1. Experimenta con los siguientes hiperparámetros para maximizar la precisión en el conjunto de prueba:\n",
        "   - **Optimizador**: Prueba `adam`, `sgd`.\n",
        "   - **Batch size**: Experimenta con `32`, `64`, `128`.\n",
        "   - **Épocas**: Prueba con `10`, `20`.\n",
        "   - **Neuronas y capas**: Varía el número de neuronas y capas densas.\n",
        "\n",
        "\n",
        "   - Documenta los hiperparámetros probados y sus resultados.\n",
        "   - Presenta los resultados en una tabla para analizar patrones.\n",
        "   - Encuentre el mejor modelo. Llamaremos este modelo MMM\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 78 Complete [00h 00m 27s]\n",
            "val_accuracy: 0.9577000141143799\n",
            "\n",
            "Best val_accuracy So Far: 0.9818000197410583\n",
            "Total elapsed time: 00h 30m 29s\n"
          ]
        }
      ],
      "source": [
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=(train_images.shape[1],)))  # Verifica que el tamaño sea correcto\n",
        "    \n",
        "    # Número de capas densas\n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        model.add(layers.Dense(\n",
        "            units=hp.Choice(f'capa{i}_neuronas', [32, 64, 128]),\n",
        "            activation='relu'\n",
        "        ))\n",
        "    \n",
        "    model.add(layers.Dense(10, activation='softmax'))  # Ajusta según el número de clases\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=hp.Choice('optimizer', ['adam', 'sgd']),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=['accuracy', tf.keras.metrics.F1Score(average='micro')]  # Corregido\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Definir el tuner para la búsqueda en grilla\n",
        "hp = kt.HyperParameters()\n",
        "\n",
        "list_hps = []\n",
        "list_train_f1 = []\n",
        "list_train_acc = []\n",
        "list_test_f1 = []\n",
        "list_test_acc = []\n",
        "list_epochs = []\n",
        "list_bs = []\n",
        "\n",
        "for epochs in [10, 20]:\n",
        "    \n",
        "    for batch_size in [32, 64, 128]:\n",
        "\n",
        "        project_name = f'GS_E{epochs}BS_{batch_size}'\n",
        "\n",
        "        tuner = kt.GridSearch(\n",
        "            build_model,\n",
        "            objective='val_accuracy',\n",
        "            executions_per_trial=1,\n",
        "            project_name=project_name,\n",
        "        )        \n",
        "\n",
        "        tuner.search(\n",
        "            train_images, to_categorical(train_labels),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(test_images, to_categorical(test_labels))\n",
        "        )\n",
        "\n",
        "        import os\n",
        "        import json\n",
        "        import pandas as pd\n",
        "\n",
        "        folder_path = project_name\n",
        "\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for dir_name in dirs:\n",
        "                dir_path = os.path.join(root, dir_name)\n",
        "                for file_name in os.listdir(dir_path):\n",
        "                    if file_name.startswith(\"trial\"):\n",
        "                        trial = os.path.join(dir_path, file_name)\n",
        "                        with open(trial, \"r\") as f:\n",
        "                            config = json.load(f)\n",
        "\n",
        "                        hps = config[\"hyperparameters\"][\"values\"]\n",
        "                        train_f1 = config[\"metrics\"][\"metrics\"][\"f1_score\"][\"observations\"][0][\"value\"][0]\n",
        "                        train_acc = config[\"metrics\"][\"metrics\"][\"accuracy\"][\"observations\"][0][\"value\"][0]\n",
        "                        val_f1 = config[\"metrics\"][\"metrics\"][\"val_f1_score\"][\"observations\"][0][\"value\"][0]\n",
        "                        val_acc = config[\"metrics\"][\"metrics\"][\"val_accuracy\"][\"observations\"][0][\"value\"][0]\n",
        "\n",
        "                        list_hps.append(hps)\n",
        "                        list_train_f1.append(train_f1)\n",
        "                        list_train_acc.append(list_train_acc)\n",
        "                        list_test_f1.append(val_f1)\n",
        "                        list_test_acc.append(val_acc)\n",
        "                        list_epochs.append(epoch)\n",
        "                        list_bs.append(batch_size)\n",
        "\n",
        "\n",
        "data = pd.DataFrame({\"Hiperparametros\": list_hps,\n",
        "                     \"epocas\" : list_epochs,\n",
        "                     \"lotes\" : list_bs,\n",
        "                     \"train_f1\": list_train_f1,\n",
        "                     \"test_f1\": list_test_f1,\n",
        "                     \"train_accuracy\": list_train_acc,\n",
        "                     \"test_accuracy\": list_test_acc,})            \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "list_hps = []\n",
        "list_train_f1 = []\n",
        "list_train_acc = []\n",
        "list_test_f1 = []\n",
        "list_test_acc = []\n",
        "list_epochs = []\n",
        "list_bs = []\n",
        "\n",
        "base_dirs = [\n",
        "    \"GS_E10BS_32\", \"GS_E10BS_64\", \"GS_E10BS_128\",\n",
        "    \"GS_E20BS_32\", \"GS_E20BS_64\", \"GS_E20BS_128\"\n",
        "]\n",
        "\n",
        "for folder_path in base_dirs:\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        if \"trial.json\" in files:\n",
        "                        with open(os.path.join(root, 'trial.json'), \"r\") as f:\n",
        "                            config = json.load(f)\n",
        "\n",
        "                        hps = config[\"hyperparameters\"][\"values\"]\n",
        "                        train_f1 = config[\"metrics\"][\"metrics\"][\"f1_score\"][\"observations\"][0][\"value\"][0]\n",
        "                        train_acc = config[\"metrics\"][\"metrics\"][\"accuracy\"][\"observations\"][0][\"value\"][0]\n",
        "                        val_f1 = config[\"metrics\"][\"metrics\"][\"val_f1_score\"][\"observations\"][0][\"value\"][0]\n",
        "                        val_acc = config[\"metrics\"][\"metrics\"][\"val_accuracy\"][\"observations\"][0][\"value\"][0]\n",
        "\n",
        "                        list_hps.append(hps)\n",
        "                        list_train_f1.append(train_f1)\n",
        "                        list_train_acc.append(train_acc)\n",
        "                        list_test_f1.append(val_f1)\n",
        "                        list_test_acc.append(val_acc)\n",
        "                        list_epochs.append(int(folder_path[-2:]))\n",
        "                        list_bs.append(int(folder_path[4:6]))\n",
        "\n",
        "data = pd.DataFrame({\"Hiperparametros\": list_hps,\n",
        "                     \"epocas\" : list_epochs,\n",
        "                     \"lotes\" : list_bs,\n",
        "                     \"train_f1\": list_train_f1,\n",
        "                     \"test_f1\": list_test_f1,\n",
        "                     \"train_accuracy\": list_train_acc,\n",
        "                     \"test_accuracy\": list_test_acc})          \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de registros cargados: 468\n",
            "Ejemplo de hiperparámetros: [{'num_layers': 1, 'capa0_neuronas': 32, 'optimizer': 'adam'}, {'num_layers': 1, 'capa0_neuronas': 32, 'optimizer': 'sgd'}]\n"
          ]
        }
      ],
      "source": [
        "print(\"Número de registros cargados:\", len(list_hps))\n",
        "print(\"Ejemplo de hiperparámetros:\", list_hps[:2])  # Muestra los primeros dos registros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.961566686630249"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_acc = config[\"metrics\"][\"metrics\"][\"accuracy\"][\"observations\"][0][\"value\"][0]\n",
        "train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.to_csv(\"output.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hiperparametros     object\n",
            "epocas               int64\n",
            "lotes                int64\n",
            "train_f1           float64\n",
            "test_f1            float64\n",
            "train_accuracy      object\n",
            "test_accuracy      float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(data.dtypes)  # Muestra los tipos de datos en cada columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Mejores hiperparámetros: {best_hps.values}\")\n",
        "#best_model = tuner.get_best_models(1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for trial in tuner.oracle.trials.values():\n",
        "    if trial.hyperparameters.values == best_hps.values:\n",
        "        print(f\"Trial ID: {trial.trial_id}\")\n",
        "        print(f\"Hiperparámetros: {trial.hyperparameters.values}\")\n",
        "        print(f\"Score: {trial.score}\")  # Si hay una métrica de evaluación\n",
        "        print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "carpeta = \"untitled_project\"\n",
        "\n",
        "for archivo in os.listdir(carpeta):\n",
        "    ruta_completa = os.path.join(carpeta, archivo)\n",
        "    if os.path.isfile(ruta_completa):  # Verifica que sea un archivo y no una carpeta\n",
        "        print(ruta_completa)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"untitled_project/trial_0001/trial.json\", \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "\n",
        "train_f1 = config[\"metrics\"][\"metrics\"][\"f1_score\"][\"observations\"][0][\"value\"][0]\n",
        "train_acc = config[\"metrics\"][\"metrics\"][\"accuracy\"][\"observations\"][0][\"value\"][0]\n",
        "val_f1 = config[\"metrics\"][\"metrics\"][\"val_f1_score\"][\"observations\"][0][\"value\"][0]\n",
        "val_acc = config[\"metrics\"][\"metrics\"][\"val_accuracy\"][\"observations\"][0][\"value\"][0]\n",
        "\n",
        "\n",
        "config[\"hyperparameters\"][\"values\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0LZxXgQhQ4t"
      },
      "source": [
        "---\n",
        "\n",
        "## Ejercicio 2: Flexibilidad Avanzada en la Definición de la Arquitectura\n",
        "\n",
        "1. Define la  arquitectura de MMM utilizando tres enfoques: **secuencial**, **funcional** y **subclassing**.\n",
        "\n",
        "2. **Preguntas**:\n",
        "   - Compara los tres enfoques:\n",
        "     - ¿Cuál es más claro y rápido de implementar?\n",
        "     - ¿Cuál es más flexible para redes personalizadas y complejas?\n",
        "   - Visualiza las estructuras usando `plot_model`.\n",
        "\n",
        "3. **Extra**:\n",
        "   - Añade una capa de normalización de lotes (**BatchNormalization**) después de cada capa oculta. Evalúa cómo afecta esto a la estructura del modelo.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Secuencial \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "hps = {'num_layers': 3, 'capa0_neuronas': 128, 'optimizer': 'adam', \n",
        "       'capa1_neuronas': 128, 'capa2_neuronas': 128}\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(hps['capa0_neuronas'], activation='relu', input_shape=(train_images.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(hps['capa1_neuronas'], activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(hps['capa2_neuronas'], activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(10, activation='sigmoid')  # Supongamos salida binaria\n",
        "])\n",
        "\n",
        "model.compile(optimizer=hps['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funcional\n",
        "\n",
        "# Entrada\n",
        "inputs = keras.Input(shape=(train_images.shape[1],))  \n",
        "\n",
        "# Capas ocultas\n",
        "x = layers.Dense(hps['capa0_neuronas'], activation='relu')(inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dense(hps['capa1_neuronas'], activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dense(hps['capa2_neuronas'], activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "# Capa de salida\n",
        "outputs = layers.Dense(10, activation='sigmoid')(x)\n",
        "\n",
        "# Definir el modelo\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer=hps['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Subclasing\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class Model(keras.Model):\n",
        "    def __init__(self, hps):\n",
        "        super(Model, self).__init__()\n",
        "        self.dense1 = layers.Dense(hps['capa0_neuronas'], activation='relu')\n",
        "        self.bn1 = layers.BatchNormalization()  # Nueva instancia\n",
        "        self.dense2 = layers.Dense(hps['capa1_neuronas'], activation='relu')\n",
        "        self.bn2 = layers.BatchNormalization()  # Nueva instancia\n",
        "        self.dense3 = layers.Dense(hps['capa2_neuronas'], activation='relu')\n",
        "        self.bn3 = layers.BatchNormalization()  # Nueva instancia\n",
        "        self.output_layer = layers.Dense(10, activation='sigmoid')\n",
        "\n",
        "        self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        inputs = tf.keras.Input(shape=(28 * 28,))\n",
        "        _ = self.call(inputs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.bn1(x)  # Aplicar BatchNormalization después de la capa densa\n",
        "        x = self.dense2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.dense3(x)\n",
        "        x = self.bn3(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "# Hiperparámetros\n",
        "hps = {'num_layers': 3, 'capa0_neuronas': 128, 'optimizer': 'adam', \n",
        "       'capa1_neuronas': 128, 'capa2_neuronas': 128}\n",
        "\n",
        "# Crear y compilar el modelo\n",
        "model = Model(hps)\n",
        "model.compile(optimizer=hps['optimizer'], loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Ejercicio 3: Explorando y Extendiendo `evaluate` y `predict`\n",
        "\n",
        "1. Investiga las opciones avanzadas de las funciones `evaluate` y `predict` en TensorFlow/Keras. Realiza un ejemplo de la utilidad de cada una.\n",
        "\n",
        "2. Investigue como cambia las metricas de desempeño de MMM cuando cambia el tamaño de lote.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Model.predict()**\n",
        "\n",
        "### **x:**\n",
        "\n",
        "- Un numpy array o una lista de arrays.\n",
        "- Un tensor o una lista de tensores.\n",
        "- Un tf.data.Dataset, útil para manejar grandes volúmenes de datos de manera eficiente.\n",
        "- Una objeto de keras.utils.PyDataset.\n",
        "\n",
        "### **batch_size:** Especifica cuántas muestras se procesan en cada iteración.\n",
        "\n",
        "Si es None, el valor predeterminado es 32.\n",
        "No debes especificarlo si x es un tf.data.Dataset, un generador o un keras.utils.PyDataset, ya que estos ya manejan los lotes automáticamente.\n",
        "\n",
        "### **verbose:** (Nivel de detalle en la salida)\n",
        "\n",
        "- \"auto\": Se comporta como 1 en la mayoría de los casos.\n",
        "- 0: No muestra nada.\n",
        "- 1: Muestra una barra de progreso.\n",
        "- 2: Muestra una línea de salida por cada iteración, útil cuando se ejecuta en producción o se guarda en un archivo de logs.\n",
        "\n",
        "### **steps** (Número total de pasos):\n",
        "\n",
        "- Si es None, se procesa hasta agotar los datos.\n",
        "- Si x es un tf.data.Dataset, y steps=None, evaluará hasta que los datos se terminen.\n",
        "- si steps=N, se ejecutarán N lotes y luego la predicción se detendrá, sin importar si hay más datos en el dataset.\n",
        "\n",
        "### **callbacks:** (Lista de funciones de callback)\n",
        "\n",
        "Los callbacks son objetos que permiten ejecutar funciones personalizadas mientras el modelo está haciendo predicciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **model.evaluate()**\n",
        "\n",
        "### **X**:\n",
        "\n",
        "- Un NumPy array o lista de NumPy arrays (si el modelo tiene múltiples entradas).\n",
        "- Un tensor o lista de tensores.\n",
        "- Un diccionario donde las claves son los nombres de las entradas del modelo y los valores son los datos correspondientes.\n",
        "- Un tf.data.Dataset, que debe devolver (inputs, targets) o (inputs, targets, sample_weights).\n",
        "- Un generador o keras.utils.PyDataset que devuelva (inputs, targets) o (inputs, targets, sample_weights).\n",
        "\n",
        "### **y** (datos de salida):\n",
        "\n",
        "Son las etiquetas o valores reales que se compararán con las predicciones del modelo.\n",
        "Deben ser un NumPy array o un tensor, igual que x.\n",
        "Si x es un tf.data.Dataset o un keras.utils.PyDataset, no se debe especificar y, ya que los datos de salida se obtienen automáticamente del dataset.\n",
        "\n",
        "### **batch_size** (tamaño del lote):\n",
        "\n",
        "Número de muestras procesadas en cada paso.\n",
        "Si no se especifica, se usa 32 por defecto.\n",
        "No usar este parámetro si x es un tf.data.Dataset, generador o keras.utils.PyDataset, ya que estos ya manejan los lotes automáticamente.\n",
        "\n",
        "### **verbose** (modo de salida):\n",
        "\n",
        "\"auto\": Modo automático (1 en la mayoría de los casos).\n",
        "0: No muestra nada (modo silencioso).\n",
        "1: Muestra una barra de progreso.\n",
        "2: Muestra solo una línea por cada paso.\n",
        "\n",
        "### **sample_weight** (pesos de muestra):\n",
        "\n",
        "Un NumPy array opcional para dar más importancia a ciertas muestras al calcular la pérdida.\n",
        "Puede ser:\n",
        "Un array 1D con el mismo número de elementos que x (cada muestra tiene un peso).\n",
        "Un array 2D con forma (muestras, longitud_secuencia), útil para datos secuenciales donde cada paso en la secuencia tiene un peso diferente.\n",
        "\n",
        "### **steps** (número de pasos o batches):\n",
        "\n",
        "Número total de lotes (batches) que se ejecutarán antes de terminar la evaluación.\n",
        "Si es None, se evaluarán todos los datos.\n",
        "Si x es un tf.data.Dataset y steps=None, la evaluación continuará hasta que el dataset se agote.\n",
        "\n",
        "### **callbacks** (funciones de retroalimentación):\n",
        "\n",
        "Lista de instancias de keras.callbacks.Callback para ejecutar acciones durante la evaluación.\n",
        "Útil para monitorear métricas o guardar información en tiempo real.\n",
        "\n",
        "### **return_dict** (formato de salida):\n",
        "\n",
        "False (por defecto): Devuelve la pérdida y las métricas como una lista de valores.\n",
        "True: Devuelve un diccionario donde las claves son los nombres de las métricas y los valores sus respectivos resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio 4: Interpretación y Análisis del Desempeño\n",
        "\n",
        "1.\n",
        "   - **Precisión por Clase**:\n",
        "     - Calcula y interpreta el desempeño del modelo para cada clase.\n",
        "   - **Matriz de Confusión**:\n",
        "     - Genera una matriz de confusión para identificar las clases más confundidas.\n",
        "   - **Confianza en las Predicciones**:\n",
        "     - Crea histogramas para visualizar la distribución de probabilidades predichas por clase.\n",
        "   - **Análisis de Errores**:\n",
        "     - Selecciona ejemplos mal clasificados, visualiza las imágenes y discute posibles razones de los errores.\n",
        "   - Encuentre el umbral de mejor desempeño en cada clase.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Cargar el JSON\n",
        "with open(\"untitled_project/trial_0068/trial.json\", \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# Extraer hiperparámetros\n",
        "hp_values = config[\"hyperparameters\"][\"values\"]\n",
        "num_layers = hp_values[\"num_layers\"]\n",
        "neurons_per_layer = [hp_values[f\"capa{i}_neuronas\"] for i in range(num_layers)]\n",
        "optimizer = hp_values[\"optimizer\"]\n",
        "\n",
        "# Construir el modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons_per_layer[0], activation=\"relu\", input_shape=(train_images.shape[1],)))  # Ajusta input_dim según tu dataset\n",
        "\n",
        "for neurons in neurons_per_layer[1:]:\n",
        "    model.add(Dense(neurons, activation=\"relu\"))\n",
        "\n",
        "model.add(Dense(10, activation=\"sigmoid\"))  # Asumiendo una salida binaria, cambia según tu caso\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Cargar pesos\n",
        "model.load_weights(\"untitled_project/trial_0068/checkpoint.weights.h5\")\n",
        "\n",
        "# Verificar la estructura\n",
        "model.summary()\n",
        "\n",
        "model.load_weights(\"untitled_project\\\\trial_0068\\\\checkpoint.weights.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 🚀 Hacer predicciones con el modelo\n",
        "y_pred_probs = model.predict(test_images)  # Probabilidades por clase\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)  # Clases predichas\n",
        "\n",
        "# 1️⃣ **Precisión por Clase**\n",
        "print(\"\\n🔹 Reporte de clasificación por clase:\")\n",
        "print(classification_report(test_labels, y_pred_classes,digits=4))\n",
        "\n",
        "\n",
        "# 2️⃣ **Matriz de Confusión**\n",
        "cm = confusion_matrix(test_labels, y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(len(cm)), yticklabels=range(len(cm)))\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Clase real\")\n",
        "plt.title(\"Matriz de Confusión\")\n",
        "plt.show()\n",
        "\n",
        "# 3️⃣ **Confianza en las Predicciones**\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(len(np.unique(test_labels))):  # Iterar por cada clase\n",
        "    plt.hist(y_pred_probs[test_labels == i, i], bins=20, alpha=0.5, label=f\"Clase {i}\")\n",
        "plt.xlabel(\"Probabilidad predicha\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.title(\"Distribución de Probabilidades Predichas por Clase\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 4️⃣ **Análisis de Errores**: Ejemplos mal clasificados\n",
        "errores_idx = np.where(y_pred_classes != test_labels)[0]  # Índices de errores\n",
        "num_ejemplos = min(20, len(errores_idx))  # Mostrar hasta 5 errores\n",
        "\n",
        "_, (imagenes_test, _) = mnist.load_data()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "filas = 4\n",
        "columnas = 5\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "for i, idx in enumerate(errores_idx[:filas * columnas]):\n",
        "    plt.subplot(filas, columnas, i + 1)\n",
        "    plt.imshow(imagenes_test[idx].squeeze(), cmap='gray')  # Ajustar si son imágenes en RGB\n",
        "    plt.title(f\"Real: {test_labels[idx]}\\nPred: {y_pred_classes[idx]}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Ejemplos Mal Clasificados\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5️⃣ **Encontrar el Mejor Umbral para cada Clase**\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "best_thresholds = {}\n",
        "for i in range(to_categorical(test_labels).shape[1]):  # Para cada clase en one-hot encoding\n",
        "    precision, recall, thresholds = precision_recall_curve(to_categorical(test_labels)[:, i], y_pred_probs[:, i])\n",
        "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    best_idx = np.argmax(f1_scores[:-1])  # Índice del mejor F1-score (evita NaN)\n",
        "    best_threshold = thresholds[best_idx]\n",
        "    best_f1 = f1_scores[best_idx]\n",
        "\n",
        "    best_thresholds[i] = (best_threshold, best_f1)  # Guardar umbral y F1-score\n",
        "\n",
        "print(\"\\n🔹 Mejor umbral y F1-score para cada clase:\")\n",
        "for cls, (thresh, f1) in best_thresholds.items():\n",
        "    print(f\"Clase {cls}: Umbral = {thresh:.4f}, F1-score = {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
